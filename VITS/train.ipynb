{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe1d498-b816-41db-9a62-ee2722474ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/espeak\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from shutil import which\n",
    "print(which('espeak'))\n",
    "print(which('espeak-ng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac87011-2c97-4b62-9bd1-f30a279bcb58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 11 17:59:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A10G                    On  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   24C    P0              57W / 300W |    582MiB / 23028MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      7613      C   ...conda3/envs/pytorch_p310/bin/python      574MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import os\n",
    "# import gdown\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import bangla\n",
    "import torch\n",
    "import pysbd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from TTS.utils.synthesizer import Synthesizer\n",
    "except:\n",
    "    print(\"coundn't import TTS synthesizer,trying again!\")\n",
    "\n",
    "import TTS\n",
    "from typing import List\n",
    "\n",
    "from TTS.config import load_config\n",
    "from TTS.tts.models import setup_model as setup_tts_model\n",
    "\n",
    "from TTS.tts.utils.synthesis import synthesis, transfer_voice, trim_silence\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.vocoder.models import setup_model as setup_vocoder_model\n",
    "from TTS.vocoder.utils.generic_utils import interpolate_vocoder_input\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = True\n",
    "pretrained = True # False\n",
    "run_name = \"VITS\"\n",
    "batch_size = 48\n",
    "eval_batch_size = 48\n",
    "num_workers = 16 # number of CPU cores\n",
    "epochs = 10000 # number of epoch\n",
    "save_step = 10000\n",
    "print_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3623c2d4-985b-4645-8567-cc35b13b8bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_path = ''\n",
    "if(pretrained):\n",
    "    pretrained_path = 'VITS-February-06-2024_11+33PM-0000000'\n",
    "if(male):\n",
    "    meta_file = 'content/iitm_bangla_tts/comprehensive_bangla_tts/male/mono/metadata_male.txt'\n",
    "    root_path = 'content/iitm_bangla_tts/comprehensive_bangla_tts/male/mono'\n",
    "else:\n",
    "    meta_file = 'content/iitm_bangla_tts/comprehensive_bangla_tts/female/mono/metadata_female.txt'\n",
    "    root_path = 'content/iitm_bangla_tts/comprehensive_bangla_tts/female/mono'\n",
    "\n",
    "def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Normalizes the LJSpeech meta data file to TTS format\n",
    "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
    "    txt_file = meta_file\n",
    "    items = []\n",
    "    speaker_name = \"ljspeech\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.join(root_path, \"wav\", cols[0] + \".wav\")\n",
    "            try:\n",
    "                text = cols[1]\n",
    "            except:\n",
    "                print(\"not found\")\n",
    "\n",
    "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "     meta_file_train=meta_file, path=os.path.join(root_path, \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "295ab8cf-33cf-4131-9968-21dc7bfdb7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 6187 files in /home/ec2-user/SageMaker/content/iitm_bangla_tts/comprehensive_bangla_tts/male/mono\n"
     ]
    }
   ],
   "source": [
    "train_samples, eval_samples = load_tts_samples(dataset_config,formatter=formatter, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcf0af6-4478-47cf-a6ab-55d999d9031f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = ''\n",
    "\n",
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=22050, \n",
    "    win_length=1024, \n",
    "    hop_length=256, \n",
    "    num_mels=80, \n",
    "    mel_fmin=0, \n",
    "    mel_fmax=None\n",
    ")\n",
    "\n",
    "\n",
    "if(male):\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '‡•§', #'<EOS>', #'‡•§',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"‡¶§‡¶ü‡ß´‡¶≠‡¶ø‡¶ê‡¶ã‡¶ñ‡¶ä‡ßú‡¶á‡¶ú‡¶Æ‡¶è‡ßá‡¶ò‡¶ô‡¶∏‡ßÄ‡ßù‡¶π‡¶û‚Äò‡¶à‡¶ï‡¶£‡ß¨‡¶Å‡ßó‡¶∂‡¶¢‡¶†\\u200c‡ßß‡ßç‡ß®‡ßÆ‡¶¶‡ßÉ‡¶î‡¶ó‡¶ì‚Äî‡¶õ‡¶â‡¶Ç‡¶¨‡ßà‡¶ù‡¶æ‡¶Ø‡¶´\\u200d‡¶ö‡¶∞‡¶∑‡¶Ö‡ßå‡ßé‡¶•‡¶°‡¶º‡ß™‡¶ß‡ß¶‡ßÅ‡ßÇ‡ß©‡¶Ü‡¶É‡¶™‡ßü‚Äô‡¶®‡¶≤‡ßã\",\n",
    "    punctuations = \"-!,|.? \",\n",
    "    )\n",
    "else:\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '‡•§', #'<EOS>', #'‡•§',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"‡¶á‡¶ó‡¶Ç‡¶º‚Äô‡ßÅ‡¶É‡¶®‡ßß‡¶ù‡ßÇ‡¶ì‚Äò‡¶ä‡ßã‡¶õ‡¶™‡¶´‡ßà‡ßÆ‡¶∑‡¶Ø‡ßé‡¶¢‡¶à‡¶ï‡¶†‡¶ø‡¶ú‡ß¶‡ß¨‡ßÄ‡¶ü‡¶°‡¶è‡¶Ö‡¶ã‡¶ß‡¶ö‡ßá‡ß®‡ß©‡¶£‡¶â‡ßü‡ßù‡¶ñ‡¶≤‡¶≠‡ßó‡¶∏‡¶π‡ßç‡ßú‡¶¶‡¶•‡¶¨‡¶î‡¶æ‡¶û‡¶∂‡¶∞‡ßå‡¶Æ‚Äî‡¶ê‡¶Ü‡ßÉ‡¶ò‡¶ô\\u200c‡¶Å‡ß™‡ß´‡¶§\",\n",
    "    punctuations = \".?-!|, \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95384b30-726e-47f1-9377-214133b9c5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VitsConfig: all model related values for training, validating and testing.\n",
    "\n",
    "config = VitsConfig(\n",
    "    audio = audio_config,\n",
    "    run_name = run_name,\n",
    "    batch_size = batch_size,\n",
    "    eval_batch_size = eval_batch_size,\n",
    "    batch_group_size = 0,\n",
    "    num_loader_workers = num_workers,\n",
    "    num_eval_loader_workers = num_workers,\n",
    "    run_eval = True,\n",
    "    test_delay_epochs = -1,\n",
    "    epochs = epochs,\n",
    "    text_cleaner = None,\n",
    "    use_phonemes = True,\n",
    "    phoneme_language = \"bn\",\n",
    "    phoneme_cache_path = os.path.join(output_path, \"bn_phoneme\"),\n",
    "    compute_input_seq_cache = True,\n",
    "    print_step = print_step,\n",
    "    print_eval = False,\n",
    "    mixed_precision = True,\n",
    "    output_path = output_path,\n",
    "    datasets = [dataset_config],\n",
    "    characters = characters_config,\n",
    "    save_step = save_step,\n",
    "    cudnn_benchmark = True,\n",
    "    test_sentences = [\n",
    "        '‡¶π‡ßü,‡¶π‡ßü‡ßá,‡¶ì‡ßü‡¶æ,‡¶π‡ßü‡ßá‡¶õ,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶¶‡¶æ‡ßü,‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü,‡¶Ü‡ßü,‡¶≠‡ßü,‡¶®‡ßü,‡¶Ü‡ßü‡¶æ‡¶§,‡¶®‡¶ø‡ßü‡ßá,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá,‡¶∞‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá‡¶õ‡ßá‡•§',\n",
    "        '‡¶¶‡ßá‡ßü,‡¶¶‡ßá‡¶ì‡ßü‡¶æ,‡¶¨‡¶ø‡¶∑‡ßü,‡¶π‡ßü,‡¶π‡¶ì‡ßü‡¶æ,‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡ßü,‡¶∏‡¶Æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡¶ø,‡¶π‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶¨‡¶ø‡¶∑‡ßü‡ßá,‡¶®‡ßü,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ,‡¶á‡ßü‡¶æ,‡¶¶‡ßá‡ßü‡¶æ,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá,‡¶Ü‡ßü‡¶æ‡¶§‡ßá,‡¶¶‡ßü‡¶æ‡•§',\n",
    "        '‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶,‡¶®‡ßü,‡¶¨‡ßç‡¶Ø‡ßü,‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶‡ßÄ,‡¶®‡ßá‡¶ì‡ßü‡¶æ,‡¶â‡¶≠‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡•§'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef0c875-ca8c-46f2-98cc-a2159fb554bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /home/ec2-user)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "fatal: not a git repository (or any parent up to mount point /home/ec2-user)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 16\n",
      " | > Num. of Torch Threads: 8\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: True\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=vits_11_jan-January-11-2024_05+59PM-0000000\n",
      "\n",
      " > Model has 83050732 parameters\n"
     ]
    }
   ],
   "source": [
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "model = Vits(config, ap, tokenizer, speaker_manager=None)\n",
    "\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(continue_path = pretrained_path),\n",
    "    config,\n",
    "    output_path,\n",
    "    model=model,\n",
    "    train_samples=train_samples,\n",
    "    eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7db4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.config.test_sentences = [\n",
    "        '‡¶π‡ßü,‡¶π‡ßü‡ßá,‡¶ì‡ßü‡¶æ,‡¶π‡ßü‡ßá‡¶õ,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶¶‡¶æ‡ßü,‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü,‡¶Ü‡ßü,‡¶≠‡ßü,‡¶®‡ßü,‡¶Ü‡ßü‡¶æ‡¶§,‡¶®‡¶ø‡ßü‡ßá,‡¶π‡ßü‡ßá‡¶õ‡ßá,‡¶¶‡¶ø‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá,‡¶∞‡ßü‡ßá‡¶õ,‡¶∞‡ßü‡ßá‡¶õ‡ßá‡•§',\n",
    "        '‡¶¶‡ßá‡ßü,‡¶¶‡ßá‡¶ì‡ßü‡¶æ,‡¶¨‡¶ø‡¶∑‡ßü,‡¶π‡ßü,‡¶π‡¶ì‡ßü‡¶æ,‡¶∏‡¶Æ‡ßç‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡ßü,‡¶∏‡¶Æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡¶ø,‡¶π‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶¨‡¶ø‡¶∑‡ßü‡ßá,‡¶®‡ßü,‡¶ï‡¶ø‡ßü‡¶æ‡¶Æ,‡¶á‡ßü‡¶æ,‡¶¶‡ßá‡ßü‡¶æ,‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßá,‡¶Ü‡ßü‡¶æ‡¶§‡ßá,‡¶¶‡ßü‡¶æ‡•§',\n",
    "        '‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶,‡¶®‡ßü,‡¶¨‡ßç‡¶Ø‡ßü,‡¶á‡ßü‡¶æ‡¶π‡ßÅ‡¶¶‡ßÄ,‡¶®‡ßá‡¶ì‡ßü‡¶æ,‡¶â‡¶≠‡ßü‡ßá,‡¶Ø‡¶æ‡ßü,‡¶π‡ßü‡ßá‡¶õ‡¶ø‡¶≤,‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡•§'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002158a-c825-404b-8e3d-c635f0f1e695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
      " --> vits_11_jan-January-11-2024_05+59PM-0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: True\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: bn\n",
      "\t\t| > phoneme backend: bn_phonemizer\n",
      "| > Number of instances : 6126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > TRAINING (2024-01-11 17:59:55) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 276735\n",
      " | > Min audio length: 49452\n",
      " | > Avg audio length: 129085.73326803787\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    }
   ],
   "source": [
    "# let's üöÄ\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fc778-0af7-45dd-9fa3-f302395920e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
